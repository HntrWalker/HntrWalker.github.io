{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AltRock.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yr9aQ82t-APB"
      },
      "source": [
        "**WIKIPEDIA DATA**\n",
        "\n",
        "**LINKS:**\n",
        "\n",
        "https://en.wikipedia.org/wiki/List_of_lists_of_lists\n",
        "\n",
        "https://en.wikipedia.org/wiki/List_of_alternative_rock_artists\n",
        "\n",
        "https://wikipedia.readthedocs.io/en/latest/code.html#api\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwtn1syf-89z"
      },
      "source": [
        "!pip install Wikipedia\n",
        "import wikipedia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSkwrrIVt3Tw"
      },
      "source": [
        "wikipedia.search(\"Alternative Rock\")\n",
        "\n",
        "alt_rock_wiki = wikipedia.page(\"List of alternative rock artists\")\n",
        "links = alt_rock_wiki.links"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IhF0wFTvfn0"
      },
      "source": [
        "titles = []\n",
        "for x in range(len(links)):\n",
        "  y = wikipedia.search(links[x])\n",
        "  titles.append(y[0])\n",
        "\n",
        "len(titles)\n",
        "\n",
        "need_cleaning = []\n",
        "for i in range(len(titles)):\n",
        "    need_cleaning.append(wikipedia.suggest(titles[i]))\n",
        "\n",
        "cleaned = []\n",
        "needs_pull = []\n",
        "for z in range(len(titles)):\n",
        "  if need_cleaning[z] == None:\n",
        "    cleaned.append(titles[z])\n",
        "\n",
        "  elif need_cleaning[z] != None:\n",
        "    needs_pull.append(titles[z])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzXO_dQfqsxI"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_cleaned = pd.DataFrame(cleaned, columns=['Titles'])\n",
        "cleaned_csv_data = df_cleaned.to_csv('cleaned.csv', index = True)\n",
        "\n",
        "df_needsPull = pd.DataFrame(needs_pull, columns=['Titles'])\n",
        "pulled_csv_data = df_needsPull.to_csv('needsPull.csv', index = True)\n",
        "\n",
        "import csv\n",
        "with open('cleaned_byHand_1.csv') as f:\n",
        "    reader = csv.reader(f)\n",
        "    cleaned_byHand = list(reader)\n",
        "print(\"csv to list:\", cleaned_byHand)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSIDDYyKwFaP"
      },
      "source": [
        "info = []\n",
        "\n",
        "for r in range(len(cleaned_byHand)):\n",
        "  info.append(wikipedia.WikipediaPage(cleaned_byHand[r]))\n",
        "\n",
        "info"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kuQ-s9AXJkC"
      },
      "source": [
        "huge_file = []\n",
        "\n",
        "for r in range(len(info)):\n",
        "  huge_file.append(info[r].content)\n",
        "\n",
        "df_huge = pd.DataFrame(huge_file, columns=['Text'])\n",
        "huge_csv_data = df_huge.to_csv('huge_file.csv', index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-PAOBbrbRh2"
      },
      "source": [
        "attempt = []\n",
        "\n",
        "for r in range(len(needs_pull)):\n",
        "  attempt.append(wikipedia.WikipediaPage(needs_pull[r]))\n",
        "\n",
        "to_be_appended = []\n",
        "\n",
        "for r in range(len(attempt)):\n",
        "  to_be_appended.append(attempt[r].content)\n",
        "\n",
        "df_appended = pd.DataFrame(to_be_appended, columns=['Text'])\n",
        "appended_csv_data = df_appended.to_csv('to_be_appended.csv', index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVg5yaYwf3Br"
      },
      "source": [
        "len(to_be_appended) + len(huge_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pafbpzMJqa2_"
      },
      "source": [
        "urls = []\n",
        "\n",
        "for r in range(len(info)):\n",
        "  urls.append(info[r].url)\n",
        "\n",
        "for r in range(len(attempt)):\n",
        "  urls.append(attempt[r].url)\n",
        "\n",
        "len(urls)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "empNVL11pHFp"
      },
      "source": [
        "urls[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gwmNbzau9Yu"
      },
      "source": [
        "# importing the module\n",
        "import requests\n",
        "import bs4\n",
        "\n",
        "URL = 'https://en.wikipedia.org/wiki/%2B44_(band)'\n",
        "\n",
        "response = requests.get(URL)\n",
        "\n",
        "soup = bs4.BeautifulSoup(response.text, 'html')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9eO91xzrrXO"
      },
      "source": [
        "infobox = soup.find('table', {'class': 'infobox'})\n",
        "\n",
        "infobox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaV_aJQZzcCZ"
      },
      "source": [
        "df_urls = pd.DataFrame(urls)\n",
        "urls_csv_data = df_urls.to_csv('urls_file.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fdqc6I5TzTss"
      },
      "source": [
        "# Getting InfoCards - Can start from here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_sLSH_LzZBQ"
      },
      "source": [
        "# First, uplaod the 'urls_file.csv' file.\n",
        "import pandas as pd\n",
        "import requests\n",
        "import bs4\n",
        "import csv\n",
        "with open('urls_file.csv') as f:\n",
        "    reader_urls = csv.reader(f)\n",
        "    urls_file = list(reader_urls)\n",
        "print(urls_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tl-Qe-1k0-ro"
      },
      "source": [
        "def output_list(masterList):\n",
        "    output = []\n",
        "    for item in masterList:\n",
        "        if isinstance(item,list):\n",
        "            for i in output_list(item): \n",
        "                output.append(i)\n",
        "        else:\n",
        "            output.append(item)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy2H8Phg3ZEE"
      },
      "source": [
        "fixed_urls = output_list(urls_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiDnrgdL6XNl"
      },
      "source": [
        "soups = []\n",
        "start_dates = []\n",
        "origins = []\n",
        "urls_final = []\n",
        "\n",
        "for r in range(len(fixed_urls)):\n",
        "  urls_final.append(fixed_urls[r])\n",
        "  url = fixed_urls[r]\n",
        "  response_url = requests.get(str(url))\n",
        "  soup = bs4.BeautifulSoup(response_url.text, 'html')\n",
        "  infobox_soup = soup.find('table', {'class': 'infobox'})\n",
        "  soups.append(infobox_soup)\n",
        "\n",
        "  stringified = str(soups[r])\n",
        "  start_year_1 = stringified.find(\"Years active\")\n",
        "\n",
        "  for element in range(start_year_1, len(stringified)): \n",
        "    if stringified[element] == '1' or stringified[element] == '2':\n",
        "      start_dates.append((stringified[element:element+4]))\n",
        "      break\n",
        "\n",
        "  origin = stringified.find(\"Origin\")\n",
        "\n",
        "  for element in range(origin+15, len(stringified)):\n",
        "    if stringified[element].isupper():\n",
        "      origins.append(stringified[element:element+30])\n",
        "      break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTASn9ILPuis"
      },
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(urls_final, columns=['URLS'])\n",
        "csv_data = df.to_csv('URLS.csv', index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpPPRGQcPw74"
      },
      "source": [
        "df_1 = pd.DataFrame(start_dates, columns=['Dates'])\n",
        "csv_data_1 = df_1.to_csv('Dates.csv', index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTxNCB8hPzLn"
      },
      "source": [
        "df_2 = pd.DataFrame(origins, columns=['Origins'])\n",
        "csv_data_2 = df_2.to_csv('Origins.csv', index = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcyygibWCyt_"
      },
      "source": [
        "# Gather Geospatial Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ww_SSL-C4wt"
      },
      "source": [
        "import csv\n",
        "with open('Locations.csv') as f:\n",
        "    reader = csv.reader(f)\n",
        "    getLat_Lon = list(reader)\n",
        "print(\"csv to list:\", getLat_Lon)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzpxWqbGDmyJ"
      },
      "source": [
        "!pip3 install geopy\n",
        "from geopy.geocoders import Nominatim\n",
        "import time\n",
        "from pprint import pprint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIn1lKUaDs0E"
      },
      "source": [
        "app = Nominatim(user_agent=\"lat_lon\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESDnlnCFD3YR"
      },
      "source": [
        "location = app.geocode(\"Los Angeles, California\").raw\n",
        "pprint(location)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ulh76qRfD9Wm"
      },
      "source": [
        "def get_location_by_address(address):\n",
        "  time.sleep(1)\n",
        "  try:\n",
        "    return app.geocode(address).raw\n",
        "  except:\n",
        "    return get_location_by_address(address)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LktYG-BFFAPK"
      },
      "source": [
        "geoData = []\n",
        "for r in range(1, len(getLat_Lon)):\n",
        "  geoData.append(get_location_by_address(str(getLat_Lon[r])))\n",
        "  print(r, geoData[r-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGJpAWiEh-9k"
      },
      "source": [
        "import csv\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qk1NE9I9iMNK"
      },
      "source": [
        "geo = pd.DataFrame.from_dict(geoData) \n",
        "geo.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH2VdHiQiSLL"
      },
      "source": [
        "geospatial_csv = geo.to_csv('geospatial.csv', index = True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}